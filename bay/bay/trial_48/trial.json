{"trial_id": "48", "hyperparameters": {"space": [{"class_name": "Int", "config": {"name": "n_hidden", "default": 2, "conditions": [], "min_value": 2, "max_value": 10, "step": 1, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "n_neurons", "default": null, "conditions": [], "min_value": 200, "max_value": 800, "step": 1, "sampling": "linear"}}, {"class_name": "Float", "config": {"name": "learning_rate", "default": 0.0001, "conditions": [], "min_value": 0.0001, "max_value": 0.01, "step": null, "sampling": "log"}}, {"class_name": "Choice", "config": {"name": "lr_scheduler", "default": "exp", "conditions": [], "values": ["exp", "poly"], "ordered": false}}, {"class_name": "Choice", "config": {"name": "optimizer", "default": "sgd", "conditions": [], "values": ["sgd", "adam"], "ordered": false}}, {"class_name": "Choice", "config": {"name": "batch_size", "default": 16, "conditions": [], "values": [16, 32], "ordered": true}}], "values": {"n_hidden": 9, "n_neurons": 277, "learning_rate": 0.003339716948396048, "lr_scheduler": "exp", "optimizer": "adam", "batch_size": 32}}, "metrics": {"metrics": {}}, "score": null, "best_step": 0, "status": "FAILED", "message": "Traceback (most recent call last):\n  File \"/home/gw3n/.conda/envs/ocr/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/gw3n/.conda/envs/ocr/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gw3n/.conda/envs/ocr/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/gw3n/.conda/envs/ocr/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_71186/3493183402.py\", line 6, in fit\n    return model.fit(\n           ^^^^^^^^^^\n  File \"/home/gw3n/.conda/envs/ocr/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/gw3n/.conda/envs/ocr/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n    except TypeError as e:\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n\nDetected at node IteratorGetNext/_2 defined at (most recent call last):\n<stack traces unavailable>\nSameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;7ed55e1ec48488e3;/job:localhost/replica:0/task:0/device:GPU:0;edge_3_IteratorGetNext;0:0\n\t [[{{node IteratorGetNext/_2}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_48800526]\n"}