{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c0a8a2-36cb-4476-b8b4-6ff1a9601374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 22:16:17.640763: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-05 22:16:17.649450: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-02-05 22:16:17.660265: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-02-05 22:16:17.663769: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-02-05 22:16:17.672008: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import random\n",
    "from pathlib import Path \n",
    "from time import strftime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449a04df-ecb6-4e01-95cb-9cab0da9e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "(X_train_all, y_train_all), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_valid, y_valid = X_train_all[-5000:], y_train_all[-5000:]\n",
    "X_train, y_train = X_train_all[:-5000], y_train_all[:-5000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea9adb-d650-4a5f-b30e-f96f87fd769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e3d786-fad9-49e9-b98f-7f50b41526af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0, 0:32, 0, 0]) # integers between zero and 255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8cb344-38bb-4e10-b5fc-25096d041061",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train / 255.)\n",
    "X_valid = (X_valid / 255.) \n",
    "X_test = (X_test / 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c745db-a855-42de-b16e-ea305e3da0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    'learning_rate' : [0.0001, 0.0005, 0.001, 0.005, 0.01], \n",
    "    'batch_size' : [16, 32, 64, 128], \n",
    "    'epochs' : [50, 100, 150, 200], \n",
    "    'num_layers' : [2, 4, 6, 8, 10],\n",
    "    'neurons' : [200, 400, 600],\n",
    "    'optimizer' : ['adam', 'sgd'],\n",
    "    'lr_sched' : ['exp', 'poly']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6413e904-ed73-41d3-8b72-2c4b65eb3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the function for the random model\n",
    "def random_model(neurons=128, num_layers=2):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=[32, 32, 3]))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(num_layers):\n",
    "        model.add(tf.keras.layers.Dense(neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73c5a3-bc8f-445a-9056-c8c2dc5ccec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_model(neurons):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=[32, 32, 3]))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428d8e80-3a1f-4752-8131-c041a871e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = []\n",
    "num_trials = 10\n",
    "for trial in range(num_trials):\n",
    "\n",
    "    lr_og = 0.0005\n",
    "    \n",
    "    end_learning_rate = 0.01\n",
    "    decay_steps = 10000\n",
    "    lr_schedule = keras.optimizers.schedules.PolynomialDecay(\n",
    "        lr_og,\n",
    "        decay_steps,\n",
    "        end_learning_rate,\n",
    "        power=0.5)\n",
    "    \n",
    "    model = other_model(neurons=600) # creating the  model\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    run_logdir = Path(\"my_logs/manual2\") / f\"trial_{trial}\"\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=100)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=200,\n",
    "        validation_data=(X_valid, y_valid), \n",
    "        callbacks=[tensorboard_cb, early_stopping_cb],\n",
    "        batch_size=128\n",
    "    )\n",
    "    \n",
    "    results2.append({\n",
    "        'final_val_acc' : max(history.history['val_accuracy']),\n",
    "        'final_train_acc' : max(history.history['accuracy']),\n",
    "        'run_id' : trial\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73b4fd-32ec-4922-a499-403dab817d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2eacd78-f208-4946-9f59-3d805bf6bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparams(param_dict):\n",
    "    list = []\n",
    "    for key, values in param_dict.items():\n",
    "        dict = {key : random.choice(values) for key, values in param_dict.items()}\n",
    "        return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc8f79-36d2-4325-b258-0e3579ad9ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir(root_logdir=\"my_logs\"):\n",
    "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18753832-3228-499e-b13a-c10af3c2243a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparams for trial 0: {'learning_rate': 0.01, 'batch_size': 64, 'epochs': 150, 'num_layers': 4, 'neurons': 400, 'optimizer': 'sgd', 'lr_sched': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1770347806.029380  642763 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1770347806.076564  642763 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1770347806.080371  642763 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1770347806.087598  642763 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1770347806.094289  642763 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1770347806.097806  642763 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1770347806.213593  642763 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1770347806.214666  642763 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1770347806.215593  642763 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-05 22:16:46.216824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1022 MB memory:  -> device: 0, name: NVIDIA RTX A400, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1770347807.906991  643367 service.cc:146] XLA service 0x7381ac004800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1770347807.907012  643367 service.cc:154]   StreamExecutor device (0): NVIDIA RTX A400, Compute Capability 8.6\n",
      "2026-02-05 22:16:47.918279: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-02-05 22:16:47.951941: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 91700\n",
      "2026-02-05 22:16:48.538766: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_63', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2026-02-05 22:16:48.844681: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "2026-02-05 22:16:49.019564: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_292', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 92/704\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1789 - loss: 2.1887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1770347810.457929  643367 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.2790 - loss: 1.9701 - val_accuracy: 0.3570 - val_loss: 1.7794\n",
      "Epoch 2/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3886 - loss: 1.6996 - val_accuracy: 0.4016 - val_loss: 1.6373\n",
      "Epoch 3/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4229 - loss: 1.5960 - val_accuracy: 0.4200 - val_loss: 1.6184\n",
      "Epoch 4/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4419 - loss: 1.5584 - val_accuracy: 0.4306 - val_loss: 1.5653\n",
      "Epoch 5/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4679 - loss: 1.4808 - val_accuracy: 0.4542 - val_loss: 1.5216\n",
      "Epoch 6/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4764 - loss: 1.4522 - val_accuracy: 0.4724 - val_loss: 1.4911\n",
      "Epoch 7/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4910 - loss: 1.4184 - val_accuracy: 0.4938 - val_loss: 1.4315\n",
      "Epoch 8/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5104 - loss: 1.3599 - val_accuracy: 0.5034 - val_loss: 1.4223\n",
      "Epoch 9/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5216 - loss: 1.3207 - val_accuracy: 0.5038 - val_loss: 1.3999\n",
      "Epoch 10/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5421 - loss: 1.2806 - val_accuracy: 0.4866 - val_loss: 1.4324\n",
      "Epoch 11/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5443 - loss: 1.2618 - val_accuracy: 0.4822 - val_loss: 1.4400\n",
      "Epoch 12/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5596 - loss: 1.2201 - val_accuracy: 0.5042 - val_loss: 1.4214\n",
      "Epoch 13/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5683 - loss: 1.1953 - val_accuracy: 0.5054 - val_loss: 1.4168\n",
      "Epoch 14/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5857 - loss: 1.1550 - val_accuracy: 0.5192 - val_loss: 1.3733\n",
      "Epoch 15/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5971 - loss: 1.1162 - val_accuracy: 0.5120 - val_loss: 1.4283\n",
      "Epoch 16/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6096 - loss: 1.0859 - val_accuracy: 0.5214 - val_loss: 1.4358\n",
      "Epoch 17/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6160 - loss: 1.0605 - val_accuracy: 0.5150 - val_loss: 1.4305\n",
      "Epoch 18/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6305 - loss: 1.0200 - val_accuracy: 0.5294 - val_loss: 1.3835\n",
      "Epoch 19/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6527 - loss: 0.9645 - val_accuracy: 0.5198 - val_loss: 1.4808\n",
      "Epoch 20/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6570 - loss: 0.9453 - val_accuracy: 0.5220 - val_loss: 1.4012\n",
      "Epoch 21/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6770 - loss: 0.8939 - val_accuracy: 0.5104 - val_loss: 1.4833\n",
      "Epoch 22/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6864 - loss: 0.8705 - val_accuracy: 0.5308 - val_loss: 1.4171\n",
      "Epoch 23/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6980 - loss: 0.8355 - val_accuracy: 0.5058 - val_loss: 1.5478\n",
      "Epoch 24/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7010 - loss: 0.8238 - val_accuracy: 0.5024 - val_loss: 1.5863\n",
      "Epoch 25/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.7635 - val_accuracy: 0.5290 - val_loss: 1.5206\n",
      "Epoch 26/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7336 - loss: 0.7351 - val_accuracy: 0.5106 - val_loss: 1.6015\n",
      "Epoch 27/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7437 - loss: 0.7065 - val_accuracy: 0.5186 - val_loss: 1.6110\n",
      "Epoch 28/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7535 - loss: 0.6804 - val_accuracy: 0.5158 - val_loss: 1.6547\n",
      "Epoch 29/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7728 - loss: 0.6342 - val_accuracy: 0.5190 - val_loss: 1.6956\n",
      "Epoch 30/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7785 - loss: 0.6055 - val_accuracy: 0.5134 - val_loss: 1.7785\n",
      "Epoch 31/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7842 - loss: 0.5988 - val_accuracy: 0.5060 - val_loss: 1.8034\n",
      "Epoch 32/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7895 - loss: 0.5764 - val_accuracy: 0.4978 - val_loss: 1.9370\n",
      "Epoch 33/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.5353 - val_accuracy: 0.5006 - val_loss: 1.9556\n",
      "Epoch 34/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.5262 - val_accuracy: 0.5090 - val_loss: 2.0386\n",
      "Epoch 35/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8134 - loss: 0.5150 - val_accuracy: 0.5152 - val_loss: 2.1370\n",
      "Epoch 36/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8252 - loss: 0.4865 - val_accuracy: 0.5080 - val_loss: 2.1263\n",
      "Epoch 37/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8314 - loss: 0.4648 - val_accuracy: 0.5180 - val_loss: 2.1693\n",
      "Epoch 38/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8305 - loss: 0.4744 - val_accuracy: 0.5048 - val_loss: 2.1935\n",
      "Epoch 39/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.4425 - val_accuracy: 0.5016 - val_loss: 2.3883\n",
      "Epoch 40/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8331 - loss: 0.4661 - val_accuracy: 0.5068 - val_loss: 2.2988\n",
      "Epoch 41/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.3989 - val_accuracy: 0.4928 - val_loss: 2.3286\n",
      "Epoch 42/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.4160 - val_accuracy: 0.5112 - val_loss: 2.2781\n",
      "Epoch 43/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.4555 - val_accuracy: 0.5026 - val_loss: 2.5583\n",
      "Epoch 44/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8510 - loss: 0.4205 - val_accuracy: 0.4960 - val_loss: 2.5480\n",
      "Hyperparams for trial 1: {'learning_rate': 0.005, 'batch_size': 64, 'epochs': 100, 'num_layers': 10, 'neurons': 200, 'optimizer': 'sgd', 'lr_sched': 'exp'}\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 22:17:57.350031: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_502', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2026-02-05 22:17:57.420956: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_502', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.1835 - loss: 2.1403 - val_accuracy: 0.3212 - val_loss: 1.8630\n",
      "Epoch 2/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3346 - loss: 1.8205 - val_accuracy: 0.3380 - val_loss: 1.8600\n",
      "Epoch 3/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3825 - loss: 1.7074 - val_accuracy: 0.3884 - val_loss: 1.6776\n",
      "Epoch 4/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4064 - loss: 1.6306 - val_accuracy: 0.4270 - val_loss: 1.6103\n",
      "Epoch 5/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4324 - loss: 1.5743 - val_accuracy: 0.4350 - val_loss: 1.5749\n",
      "Epoch 6/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4457 - loss: 1.5450 - val_accuracy: 0.4476 - val_loss: 1.5359\n",
      "Epoch 7/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4616 - loss: 1.4988 - val_accuracy: 0.4530 - val_loss: 1.5171\n",
      "Epoch 8/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4754 - loss: 1.4640 - val_accuracy: 0.4612 - val_loss: 1.5039\n",
      "Epoch 9/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4868 - loss: 1.4360 - val_accuracy: 0.4718 - val_loss: 1.4690\n",
      "Epoch 10/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4912 - loss: 1.4200 - val_accuracy: 0.4628 - val_loss: 1.5217\n",
      "Epoch 11/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4993 - loss: 1.3869 - val_accuracy: 0.4860 - val_loss: 1.4493\n",
      "Epoch 12/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5188 - loss: 1.3426 - val_accuracy: 0.4850 - val_loss: 1.4547\n",
      "Epoch 13/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5187 - loss: 1.3405 - val_accuracy: 0.4950 - val_loss: 1.4105\n",
      "Epoch 14/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5271 - loss: 1.3067 - val_accuracy: 0.4736 - val_loss: 1.4761\n",
      "Epoch 15/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5360 - loss: 1.2886 - val_accuracy: 0.5098 - val_loss: 1.3831\n",
      "Epoch 16/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5535 - loss: 1.2567 - val_accuracy: 0.5058 - val_loss: 1.3963\n",
      "Epoch 17/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5559 - loss: 1.2411 - val_accuracy: 0.5040 - val_loss: 1.3997\n",
      "Epoch 18/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5639 - loss: 1.2183 - val_accuracy: 0.5054 - val_loss: 1.4086\n",
      "Epoch 19/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5723 - loss: 1.1935 - val_accuracy: 0.5158 - val_loss: 1.3931\n",
      "Epoch 20/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5793 - loss: 1.1738 - val_accuracy: 0.5216 - val_loss: 1.3879\n",
      "Epoch 21/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5846 - loss: 1.1561 - val_accuracy: 0.4838 - val_loss: 1.4797\n",
      "Epoch 22/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5869 - loss: 1.1498 - val_accuracy: 0.5168 - val_loss: 1.3841\n",
      "Epoch 23/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5989 - loss: 1.1208 - val_accuracy: 0.5220 - val_loss: 1.3985\n",
      "Epoch 24/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6048 - loss: 1.1112 - val_accuracy: 0.5188 - val_loss: 1.4027\n",
      "Epoch 25/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6160 - loss: 1.0808 - val_accuracy: 0.5246 - val_loss: 1.3972\n",
      "Epoch 26/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6212 - loss: 1.0662 - val_accuracy: 0.5176 - val_loss: 1.4346\n",
      "Epoch 27/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6269 - loss: 1.0517 - val_accuracy: 0.5220 - val_loss: 1.4222\n",
      "Epoch 28/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6364 - loss: 1.0062 - val_accuracy: 0.5202 - val_loss: 1.4258\n",
      "Epoch 29/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6405 - loss: 1.0078 - val_accuracy: 0.5178 - val_loss: 1.4422\n",
      "Epoch 30/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6434 - loss: 0.9926 - val_accuracy: 0.5190 - val_loss: 1.4219\n",
      "Epoch 31/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6625 - loss: 0.9535 - val_accuracy: 0.5326 - val_loss: 1.4139\n",
      "Epoch 32/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6627 - loss: 0.9351 - val_accuracy: 0.4962 - val_loss: 1.5064\n",
      "Epoch 33/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6733 - loss: 0.9249 - val_accuracy: 0.5140 - val_loss: 1.4826\n",
      "Epoch 34/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6764 - loss: 0.9030 - val_accuracy: 0.5016 - val_loss: 1.5239\n",
      "Epoch 35/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6764 - loss: 0.9023 - val_accuracy: 0.5078 - val_loss: 1.4838\n",
      "Epoch 36/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6823 - loss: 0.8804 - val_accuracy: 0.5288 - val_loss: 1.5030\n",
      "Epoch 37/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6865 - loss: 0.8826 - val_accuracy: 0.5136 - val_loss: 1.5252\n",
      "Epoch 38/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7049 - loss: 0.8329 - val_accuracy: 0.5158 - val_loss: 1.5615\n",
      "Epoch 39/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7056 - loss: 0.8183 - val_accuracy: 0.5104 - val_loss: 1.5937\n",
      "Epoch 40/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.8154 - val_accuracy: 0.4906 - val_loss: 1.6234\n",
      "Epoch 41/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7041 - loss: 0.8222 - val_accuracy: 0.5090 - val_loss: 1.6080\n",
      "Epoch 42/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.7802 - val_accuracy: 0.5210 - val_loss: 1.5501\n",
      "Epoch 43/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.7807 - val_accuracy: 0.5074 - val_loss: 1.6592\n",
      "Epoch 44/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.7440 - val_accuracy: 0.5066 - val_loss: 1.7076\n",
      "Epoch 45/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7340 - loss: 0.7403 - val_accuracy: 0.4992 - val_loss: 1.6596\n",
      "Hyperparams for trial 2: {'learning_rate': 0.0001, 'batch_size': 16, 'epochs': 50, 'num_layers': 2, 'neurons': 600, 'optimizer': 'adam', 'lr_sched': 'exp'}\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 22:19:10.538259: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_155', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2999 - loss: 1.9336 - val_accuracy: 0.3892 - val_loss: 1.7011\n",
      "Epoch 2/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.4155 - loss: 1.6433 - val_accuracy: 0.4408 - val_loss: 1.5974\n",
      "Epoch 3/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.4482 - loss: 1.5509 - val_accuracy: 0.4590 - val_loss: 1.5274\n",
      "Epoch 4/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.4775 - loss: 1.4801 - val_accuracy: 0.4760 - val_loss: 1.4824\n",
      "Epoch 5/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.4927 - loss: 1.4258 - val_accuracy: 0.4842 - val_loss: 1.4612\n",
      "Epoch 6/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5110 - loss: 1.3856 - val_accuracy: 0.4810 - val_loss: 1.4817\n",
      "Epoch 7/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5243 - loss: 1.3403 - val_accuracy: 0.5134 - val_loss: 1.3950\n",
      "Epoch 8/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5371 - loss: 1.3076 - val_accuracy: 0.5102 - val_loss: 1.3947\n",
      "Epoch 9/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5578 - loss: 1.2571 - val_accuracy: 0.5126 - val_loss: 1.3850\n",
      "Epoch 10/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5587 - loss: 1.2381 - val_accuracy: 0.5208 - val_loss: 1.3683\n",
      "Epoch 11/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5794 - loss: 1.1998 - val_accuracy: 0.5118 - val_loss: 1.3691\n",
      "Epoch 12/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5901 - loss: 1.1589 - val_accuracy: 0.5146 - val_loss: 1.4086\n",
      "Epoch 13/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 1.1432 - val_accuracy: 0.5414 - val_loss: 1.3291\n",
      "Epoch 14/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6080 - loss: 1.1042 - val_accuracy: 0.5224 - val_loss: 1.3687\n",
      "Epoch 15/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6218 - loss: 1.0783 - val_accuracy: 0.5374 - val_loss: 1.3464\n",
      "Epoch 16/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6356 - loss: 1.0435 - val_accuracy: 0.5368 - val_loss: 1.3234\n",
      "Epoch 17/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6407 - loss: 1.0209 - val_accuracy: 0.5444 - val_loss: 1.3276\n",
      "Epoch 18/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6554 - loss: 0.9906 - val_accuracy: 0.5326 - val_loss: 1.3862\n",
      "Epoch 19/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6594 - loss: 0.9636 - val_accuracy: 0.5312 - val_loss: 1.3555\n",
      "Epoch 20/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6754 - loss: 0.9271 - val_accuracy: 0.5498 - val_loss: 1.3465\n",
      "Epoch 21/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6876 - loss: 0.9010 - val_accuracy: 0.5340 - val_loss: 1.4068\n",
      "Epoch 22/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6908 - loss: 0.8738 - val_accuracy: 0.5470 - val_loss: 1.3640\n",
      "Epoch 23/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7050 - loss: 0.8493 - val_accuracy: 0.5530 - val_loss: 1.3933\n",
      "Epoch 24/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7148 - loss: 0.8186 - val_accuracy: 0.5434 - val_loss: 1.4015\n",
      "Epoch 25/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 0.8003 - val_accuracy: 0.5408 - val_loss: 1.4166\n",
      "Epoch 26/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7343 - loss: 0.7740 - val_accuracy: 0.5540 - val_loss: 1.4034\n",
      "Epoch 27/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7414 - loss: 0.7489 - val_accuracy: 0.5486 - val_loss: 1.4216\n",
      "Epoch 28/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7495 - loss: 0.7286 - val_accuracy: 0.5380 - val_loss: 1.4759\n",
      "Epoch 29/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7556 - loss: 0.6997 - val_accuracy: 0.5472 - val_loss: 1.4439\n",
      "Epoch 30/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7635 - loss: 0.6775 - val_accuracy: 0.5444 - val_loss: 1.4696\n",
      "Epoch 31/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7761 - loss: 0.6512 - val_accuracy: 0.5434 - val_loss: 1.5219\n",
      "Epoch 32/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7832 - loss: 0.6273 - val_accuracy: 0.5484 - val_loss: 1.5499\n",
      "Epoch 33/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7910 - loss: 0.6131 - val_accuracy: 0.5510 - val_loss: 1.5326\n",
      "Epoch 34/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.5894 - val_accuracy: 0.5438 - val_loss: 1.5716\n",
      "Epoch 35/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.5569 - val_accuracy: 0.5494 - val_loss: 1.5694\n",
      "Epoch 36/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8215 - loss: 0.5367 - val_accuracy: 0.5400 - val_loss: 1.6299\n",
      "Epoch 37/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.5120 - val_accuracy: 0.5420 - val_loss: 1.6258\n",
      "Epoch 38/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8318 - loss: 0.4966 - val_accuracy: 0.5496 - val_loss: 1.6208\n",
      "Epoch 39/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.4745 - val_accuracy: 0.5480 - val_loss: 1.6727\n",
      "Epoch 40/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8460 - loss: 0.4594 - val_accuracy: 0.5432 - val_loss: 1.7273\n",
      "Epoch 41/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.4426 - val_accuracy: 0.5420 - val_loss: 1.7540\n",
      "Epoch 42/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8567 - loss: 0.4328 - val_accuracy: 0.5464 - val_loss: 1.7706\n",
      "Epoch 43/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8667 - loss: 0.4049 - val_accuracy: 0.5386 - val_loss: 1.8055\n",
      "Epoch 44/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8713 - loss: 0.3933 - val_accuracy: 0.5448 - val_loss: 1.8191\n",
      "Epoch 45/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.3683 - val_accuracy: 0.5412 - val_loss: 1.8277\n",
      "Epoch 46/50\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.3602 - val_accuracy: 0.5468 - val_loss: 1.8459\n",
      "Hyperparams for trial 3: {'learning_rate': 0.0005, 'batch_size': 64, 'epochs': 200, 'num_layers': 6, 'neurons': 400, 'optimizer': 'sgd', 'lr_sched': 'exp'}\n",
      "Epoch 1/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1550 - loss: 2.2373 - val_accuracy: 0.2800 - val_loss: 1.9817\n",
      "Epoch 2/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3062 - loss: 1.9242 - val_accuracy: 0.3404 - val_loss: 1.8378\n",
      "Epoch 3/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3535 - loss: 1.8026 - val_accuracy: 0.3574 - val_loss: 1.7694\n",
      "Epoch 4/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3811 - loss: 1.7382 - val_accuracy: 0.3702 - val_loss: 1.7381\n",
      "Epoch 5/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3999 - loss: 1.6771 - val_accuracy: 0.4088 - val_loss: 1.6540\n",
      "Epoch 6/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4137 - loss: 1.6345 - val_accuracy: 0.4240 - val_loss: 1.6327\n",
      "Epoch 7/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4255 - loss: 1.6067 - val_accuracy: 0.4286 - val_loss: 1.6111\n",
      "Epoch 8/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4396 - loss: 1.5554 - val_accuracy: 0.4426 - val_loss: 1.5521\n",
      "Epoch 9/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4543 - loss: 1.5236 - val_accuracy: 0.4328 - val_loss: 1.6200\n",
      "Epoch 10/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4660 - loss: 1.4969 - val_accuracy: 0.4574 - val_loss: 1.5340\n",
      "Epoch 11/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4733 - loss: 1.4704 - val_accuracy: 0.4510 - val_loss: 1.5480\n",
      "Epoch 12/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4820 - loss: 1.4497 - val_accuracy: 0.4760 - val_loss: 1.4683\n",
      "Epoch 13/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4902 - loss: 1.4244 - val_accuracy: 0.4662 - val_loss: 1.4713\n",
      "Epoch 14/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4964 - loss: 1.4014 - val_accuracy: 0.4770 - val_loss: 1.4506\n",
      "Epoch 15/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5042 - loss: 1.3812 - val_accuracy: 0.4932 - val_loss: 1.4087\n",
      "Epoch 16/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 1.3636 - val_accuracy: 0.4980 - val_loss: 1.3927\n",
      "Epoch 17/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5181 - loss: 1.3394 - val_accuracy: 0.4958 - val_loss: 1.4123\n",
      "Epoch 18/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5272 - loss: 1.3210 - val_accuracy: 0.4958 - val_loss: 1.4299\n",
      "Epoch 19/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5336 - loss: 1.3023 - val_accuracy: 0.5062 - val_loss: 1.3777\n",
      "Epoch 20/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5432 - loss: 1.2831 - val_accuracy: 0.5018 - val_loss: 1.3906\n",
      "Epoch 21/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5434 - loss: 1.2756 - val_accuracy: 0.5132 - val_loss: 1.3646\n",
      "Epoch 22/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5585 - loss: 1.2417 - val_accuracy: 0.5076 - val_loss: 1.3842\n",
      "Epoch 23/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5580 - loss: 1.2386 - val_accuracy: 0.5022 - val_loss: 1.3957\n",
      "Epoch 24/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5697 - loss: 1.2147 - val_accuracy: 0.5130 - val_loss: 1.3634\n",
      "Epoch 25/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5729 - loss: 1.1928 - val_accuracy: 0.5054 - val_loss: 1.3891\n",
      "Epoch 26/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5744 - loss: 1.1934 - val_accuracy: 0.5136 - val_loss: 1.3606\n",
      "Epoch 27/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5775 - loss: 1.1768 - val_accuracy: 0.5154 - val_loss: 1.3517\n",
      "Epoch 28/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5858 - loss: 1.1556 - val_accuracy: 0.5210 - val_loss: 1.3552\n",
      "Epoch 29/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5891 - loss: 1.1477 - val_accuracy: 0.5144 - val_loss: 1.3779\n",
      "Epoch 30/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5962 - loss: 1.1324 - val_accuracy: 0.5182 - val_loss: 1.4140\n",
      "Epoch 31/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6018 - loss: 1.1169 - val_accuracy: 0.5130 - val_loss: 1.3892\n",
      "Epoch 32/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 1.0864 - val_accuracy: 0.5296 - val_loss: 1.3509\n",
      "Epoch 33/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6112 - loss: 1.0860 - val_accuracy: 0.5392 - val_loss: 1.3193\n",
      "Epoch 34/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6143 - loss: 1.0759 - val_accuracy: 0.5382 - val_loss: 1.3345\n",
      "Epoch 35/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6285 - loss: 1.0456 - val_accuracy: 0.5368 - val_loss: 1.3330\n",
      "Epoch 36/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6340 - loss: 1.0226 - val_accuracy: 0.5314 - val_loss: 1.3313\n",
      "Epoch 37/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6413 - loss: 0.9946 - val_accuracy: 0.5274 - val_loss: 1.3571\n",
      "Epoch 38/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6438 - loss: 0.9916 - val_accuracy: 0.4954 - val_loss: 1.4960\n",
      "Epoch 39/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6465 - loss: 0.9932 - val_accuracy: 0.5312 - val_loss: 1.3419\n",
      "Epoch 40/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6519 - loss: 0.9767 - val_accuracy: 0.5384 - val_loss: 1.3538\n",
      "Epoch 41/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6541 - loss: 0.9566 - val_accuracy: 0.5252 - val_loss: 1.3975\n",
      "Epoch 42/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6628 - loss: 0.9399 - val_accuracy: 0.5178 - val_loss: 1.4538\n",
      "Epoch 43/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6674 - loss: 0.9378 - val_accuracy: 0.5172 - val_loss: 1.4132\n",
      "Epoch 44/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6707 - loss: 0.9205 - val_accuracy: 0.5436 - val_loss: 1.3684\n",
      "Epoch 45/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6768 - loss: 0.9065 - val_accuracy: 0.5424 - val_loss: 1.3844\n",
      "Epoch 46/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6829 - loss: 0.8833 - val_accuracy: 0.5332 - val_loss: 1.4054\n",
      "Epoch 47/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6897 - loss: 0.8741 - val_accuracy: 0.5260 - val_loss: 1.4343\n",
      "Epoch 48/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6970 - loss: 0.8453 - val_accuracy: 0.5072 - val_loss: 1.5346\n",
      "Epoch 49/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6958 - loss: 0.8469 - val_accuracy: 0.5274 - val_loss: 1.4316\n",
      "Epoch 50/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7027 - loss: 0.8318 - val_accuracy: 0.5380 - val_loss: 1.4435\n",
      "Epoch 51/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.8017 - val_accuracy: 0.5276 - val_loss: 1.4674\n",
      "Epoch 52/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.7844 - val_accuracy: 0.5260 - val_loss: 1.4824\n",
      "Epoch 53/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: 0.7767 - val_accuracy: 0.5142 - val_loss: 1.5444\n",
      "Epoch 54/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7099 - loss: 0.8036 - val_accuracy: 0.5364 - val_loss: 1.4513\n",
      "Epoch 55/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.7431 - val_accuracy: 0.5140 - val_loss: 1.5252\n",
      "Epoch 56/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7367 - loss: 0.7377 - val_accuracy: 0.5104 - val_loss: 1.5683\n",
      "Epoch 57/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7390 - loss: 0.7263 - val_accuracy: 0.5080 - val_loss: 1.6022\n",
      "Epoch 58/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7489 - loss: 0.7022 - val_accuracy: 0.5372 - val_loss: 1.4861\n",
      "Epoch 59/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7584 - loss: 0.6731 - val_accuracy: 0.5340 - val_loss: 1.5301\n",
      "Epoch 60/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7521 - loss: 0.6834 - val_accuracy: 0.5040 - val_loss: 1.7099\n",
      "Epoch 61/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7642 - loss: 0.6657 - val_accuracy: 0.5308 - val_loss: 1.5890\n",
      "Epoch 62/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7675 - loss: 0.6569 - val_accuracy: 0.5356 - val_loss: 1.6139\n",
      "Epoch 63/200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7699 - loss: 0.6403 - val_accuracy: 0.5196 - val_loss: 1.7746\n",
      "Hyperparams for trial 4: {'learning_rate': 0.001, 'batch_size': 32, 'epochs': 150, 'num_layers': 6, 'neurons': 400, 'optimizer': 'sgd', 'lr_sched': 'poly'}\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 22:25:15.114074: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_362', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2026-02-05 22:25:15.277263: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_362', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2026-02-05 22:25:15.653676: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_362', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2376 - loss: 2.0800 - val_accuracy: 0.3586 - val_loss: 1.7749\n",
      "Epoch 2/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3739 - loss: 1.7346 - val_accuracy: 0.4002 - val_loss: 1.6696\n",
      "Epoch 3/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4099 - loss: 1.6381 - val_accuracy: 0.4154 - val_loss: 1.6322\n",
      "Epoch 4/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4338 - loss: 1.5739 - val_accuracy: 0.4482 - val_loss: 1.5383\n",
      "Epoch 5/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4504 - loss: 1.5330 - val_accuracy: 0.4294 - val_loss: 1.5767\n",
      "Epoch 6/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4564 - loss: 1.5176 - val_accuracy: 0.4256 - val_loss: 1.6300\n",
      "Epoch 7/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4533 - loss: 1.5180 - val_accuracy: 0.4502 - val_loss: 1.5578\n",
      "Epoch 8/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4605 - loss: 1.5010 - val_accuracy: 0.4356 - val_loss: 1.5856\n",
      "Epoch 9/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4780 - loss: 1.4661 - val_accuracy: 0.4826 - val_loss: 1.4711\n",
      "Epoch 10/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4954 - loss: 1.4070 - val_accuracy: 0.4814 - val_loss: 1.4733\n",
      "Epoch 11/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5056 - loss: 1.3734 - val_accuracy: 0.4416 - val_loss: 1.5782\n",
      "Epoch 12/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5181 - loss: 1.3423 - val_accuracy: 0.4786 - val_loss: 1.4774\n",
      "Epoch 13/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5302 - loss: 1.3000 - val_accuracy: 0.4898 - val_loss: 1.4376\n",
      "Epoch 14/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5485 - loss: 1.2583 - val_accuracy: 0.5020 - val_loss: 1.4146\n",
      "Epoch 15/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5545 - loss: 1.2343 - val_accuracy: 0.4806 - val_loss: 1.4734\n",
      "Epoch 16/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5675 - loss: 1.2036 - val_accuracy: 0.5216 - val_loss: 1.3843\n",
      "Epoch 17/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5809 - loss: 1.1716 - val_accuracy: 0.5114 - val_loss: 1.3810\n",
      "Epoch 18/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5916 - loss: 1.1381 - val_accuracy: 0.5116 - val_loss: 1.4114\n",
      "Epoch 19/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5998 - loss: 1.1018 - val_accuracy: 0.5098 - val_loss: 1.4301\n",
      "Epoch 20/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6112 - loss: 1.0716 - val_accuracy: 0.5062 - val_loss: 1.4531\n",
      "Epoch 21/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6219 - loss: 1.0415 - val_accuracy: 0.4840 - val_loss: 1.5711\n",
      "Epoch 22/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6345 - loss: 1.0068 - val_accuracy: 0.5252 - val_loss: 1.4158\n",
      "Epoch 23/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6469 - loss: 0.9744 - val_accuracy: 0.5222 - val_loss: 1.4567\n",
      "Epoch 24/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6523 - loss: 0.9568 - val_accuracy: 0.5020 - val_loss: 1.5050\n",
      "Epoch 25/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6633 - loss: 0.9208 - val_accuracy: 0.5218 - val_loss: 1.4857\n",
      "Epoch 26/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6706 - loss: 0.9063 - val_accuracy: 0.5208 - val_loss: 1.5067\n",
      "Epoch 27/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6792 - loss: 0.8762 - val_accuracy: 0.5050 - val_loss: 1.5288\n",
      "Epoch 28/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6873 - loss: 0.8680 - val_accuracy: 0.5102 - val_loss: 1.6171\n",
      "Epoch 29/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6929 - loss: 0.8445 - val_accuracy: 0.5112 - val_loss: 1.6750\n",
      "Epoch 30/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6972 - loss: 0.8405 - val_accuracy: 0.5234 - val_loss: 1.5324\n",
      "Epoch 31/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7058 - loss: 0.8081 - val_accuracy: 0.5070 - val_loss: 1.6128\n",
      "Epoch 32/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7197 - loss: 0.7779 - val_accuracy: 0.5090 - val_loss: 1.6795\n",
      "Epoch 33/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.7582 - val_accuracy: 0.5162 - val_loss: 1.7095\n",
      "Epoch 34/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7306 - loss: 0.7490 - val_accuracy: 0.5198 - val_loss: 1.6970\n",
      "Epoch 35/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7397 - loss: 0.7195 - val_accuracy: 0.5106 - val_loss: 1.6598\n",
      "Epoch 36/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7415 - loss: 0.7171 - val_accuracy: 0.5006 - val_loss: 1.7219\n",
      "Epoch 37/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7389 - loss: 0.7162 - val_accuracy: 0.5322 - val_loss: 1.7209\n",
      "Epoch 38/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.6874 - val_accuracy: 0.5120 - val_loss: 1.8339\n",
      "Epoch 39/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7528 - loss: 0.6848 - val_accuracy: 0.5134 - val_loss: 1.7886\n",
      "Epoch 40/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7512 - loss: 0.6874 - val_accuracy: 0.4916 - val_loss: 1.8091\n",
      "Epoch 41/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7622 - loss: 0.6622 - val_accuracy: 0.5080 - val_loss: 1.9416\n",
      "Epoch 42/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.6436 - val_accuracy: 0.5156 - val_loss: 1.8562\n",
      "Epoch 43/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7671 - loss: 0.6535 - val_accuracy: 0.4960 - val_loss: 1.9784\n",
      "Epoch 44/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7732 - loss: 0.6442 - val_accuracy: 0.5208 - val_loss: 1.8480\n",
      "Epoch 45/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7760 - loss: 0.6354 - val_accuracy: 0.5156 - val_loss: 1.9230\n",
      "Epoch 46/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7817 - loss: 0.6225 - val_accuracy: 0.5082 - val_loss: 1.9152\n",
      "Epoch 47/150\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7810 - loss: 0.6195 - val_accuracy: 0.5112 - val_loss: 2.0251\n",
      "Hyperparams for trial 5: {'learning_rate': 0.005, 'batch_size': 128, 'epochs': 50, 'num_layers': 6, 'neurons': 400, 'optimizer': 'adam', 'lr_sched': 'exp'}\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 22:27:29.615238: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_291', 320 bytes spill stores, 320 bytes spill loads\n",
      "\n",
      "2026-02-05 22:27:30.098680: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_291', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2026-02-05 22:27:30.134635: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_582', 124 bytes spill stores, 124 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m345/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1310 - loss: 2.7985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 22:27:33.115175: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_291', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "2026-02-05 22:27:33.551817: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_291', 384 bytes spill stores, 376 bytes spill loads\n",
      "\n",
      "2026-02-05 22:27:33.556017: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_291', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2026-02-05 22:27:34.013700: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_582', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "2026-02-05 22:27:34.144045: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_582', 40 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2026-02-05 22:27:34.213297: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_582', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.1320 - loss: 2.7859 - val_accuracy: 0.2200 - val_loss: 2.0204\n",
      "Epoch 2/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2590 - loss: 1.9647 - val_accuracy: 0.3028 - val_loss: 1.8552\n",
      "Epoch 3/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3084 - loss: 1.8579 - val_accuracy: 0.3232 - val_loss: 1.8335\n",
      "Epoch 4/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3320 - loss: 1.8099 - val_accuracy: 0.3558 - val_loss: 1.7739\n",
      "Epoch 5/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3602 - loss: 1.7592 - val_accuracy: 0.3280 - val_loss: 1.8213\n",
      "Epoch 6/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3609 - loss: 1.7497 - val_accuracy: 0.3858 - val_loss: 1.7376\n",
      "Epoch 7/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3779 - loss: 1.7076 - val_accuracy: 0.3910 - val_loss: 1.7117\n",
      "Epoch 8/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3865 - loss: 1.6849 - val_accuracy: 0.3628 - val_loss: 1.7456\n",
      "Epoch 9/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3914 - loss: 1.6791 - val_accuracy: 0.4010 - val_loss: 1.6845\n",
      "Epoch 10/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4025 - loss: 1.6422 - val_accuracy: 0.3950 - val_loss: 1.6932\n",
      "Epoch 11/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4046 - loss: 1.6361 - val_accuracy: 0.4016 - val_loss: 1.6898\n",
      "Epoch 12/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4089 - loss: 1.6426 - val_accuracy: 0.3956 - val_loss: 1.6821\n",
      "Epoch 13/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4153 - loss: 1.6237 - val_accuracy: 0.4104 - val_loss: 1.6510\n",
      "Epoch 14/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4194 - loss: 1.6025 - val_accuracy: 0.4176 - val_loss: 1.6378\n",
      "Epoch 15/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4308 - loss: 1.5840 - val_accuracy: 0.4250 - val_loss: 1.6233\n",
      "Epoch 16/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4256 - loss: 1.6002 - val_accuracy: 0.4094 - val_loss: 1.6552\n",
      "Epoch 17/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4271 - loss: 1.5905 - val_accuracy: 0.4088 - val_loss: 1.6225\n",
      "Epoch 18/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4236 - loss: 1.5903 - val_accuracy: 0.4266 - val_loss: 1.6345\n",
      "Epoch 19/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4376 - loss: 1.5671 - val_accuracy: 0.4184 - val_loss: 1.6335\n",
      "Epoch 20/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4369 - loss: 1.5654 - val_accuracy: 0.4178 - val_loss: 1.6075\n",
      "Epoch 21/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4306 - loss: 1.5765 - val_accuracy: 0.4248 - val_loss: 1.6234\n",
      "Epoch 22/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4409 - loss: 1.5619 - val_accuracy: 0.4290 - val_loss: 1.6144\n",
      "Epoch 23/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4457 - loss: 1.5473 - val_accuracy: 0.4164 - val_loss: 1.6177\n",
      "Epoch 24/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4444 - loss: 1.5418 - val_accuracy: 0.4262 - val_loss: 1.6089\n",
      "Epoch 25/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4442 - loss: 1.5403 - val_accuracy: 0.4322 - val_loss: 1.6066\n",
      "Epoch 26/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4389 - loss: 1.5549 - val_accuracy: 0.4240 - val_loss: 1.6176\n",
      "Epoch 27/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4428 - loss: 1.5473 - val_accuracy: 0.4266 - val_loss: 1.6107\n",
      "Epoch 28/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4435 - loss: 1.5381 - val_accuracy: 0.4254 - val_loss: 1.6138\n",
      "Epoch 29/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4452 - loss: 1.5410 - val_accuracy: 0.4184 - val_loss: 1.6127\n",
      "Epoch 30/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4453 - loss: 1.5468 - val_accuracy: 0.4302 - val_loss: 1.6165\n",
      "Epoch 31/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4436 - loss: 1.5466 - val_accuracy: 0.4336 - val_loss: 1.5892\n",
      "Epoch 32/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4426 - loss: 1.5436 - val_accuracy: 0.4112 - val_loss: 1.6795\n",
      "Epoch 33/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4490 - loss: 1.5395 - val_accuracy: 0.4270 - val_loss: 1.5944\n",
      "Epoch 34/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4417 - loss: 1.5437 - val_accuracy: 0.4456 - val_loss: 1.5896\n",
      "Epoch 35/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4484 - loss: 1.5282 - val_accuracy: 0.4022 - val_loss: 1.6562\n",
      "Epoch 36/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4452 - loss: 1.5391 - val_accuracy: 0.4186 - val_loss: 1.6234\n",
      "Epoch 37/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4464 - loss: 1.5253 - val_accuracy: 0.4250 - val_loss: 1.6154\n",
      "Epoch 38/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4532 - loss: 1.5254 - val_accuracy: 0.4262 - val_loss: 1.6235\n",
      "Epoch 39/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4546 - loss: 1.5103 - val_accuracy: 0.4200 - val_loss: 1.6040\n",
      "Epoch 40/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4563 - loss: 1.5089 - val_accuracy: 0.4352 - val_loss: 1.6031\n",
      "Epoch 41/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4646 - loss: 1.4940 - val_accuracy: 0.4340 - val_loss: 1.5917\n",
      "Epoch 42/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4650 - loss: 1.4934 - val_accuracy: 0.4466 - val_loss: 1.5734\n",
      "Epoch 43/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4596 - loss: 1.5025 - val_accuracy: 0.4244 - val_loss: 1.6051\n",
      "Epoch 44/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4607 - loss: 1.4926 - val_accuracy: 0.4316 - val_loss: 1.5872\n",
      "Epoch 45/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4604 - loss: 1.4940 - val_accuracy: 0.4354 - val_loss: 1.5744\n",
      "Epoch 46/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4582 - loss: 1.4980 - val_accuracy: 0.4380 - val_loss: 1.5768\n",
      "Epoch 47/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4646 - loss: 1.4838 - val_accuracy: 0.4362 - val_loss: 1.6055\n",
      "Epoch 48/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4639 - loss: 1.4925 - val_accuracy: 0.4312 - val_loss: 1.6228\n",
      "Epoch 49/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4601 - loss: 1.5077 - val_accuracy: 0.4334 - val_loss: 1.5974\n",
      "Epoch 50/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4593 - loss: 1.4944 - val_accuracy: 0.4136 - val_loss: 1.6812\n",
      "Hyperparams for trial 6: {'learning_rate': 0.0001, 'batch_size': 64, 'epochs': 100, 'num_layers': 10, 'neurons': 200, 'optimizer': 'sgd', 'lr_sched': 'exp'}\n",
      "Epoch 1/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1130 - loss: 2.3016 - val_accuracy: 0.1450 - val_loss: 2.2985\n",
      "Epoch 2/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1435 - loss: 2.2982 - val_accuracy: 0.1530 - val_loss: 2.2943\n",
      "Epoch 3/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1507 - loss: 2.2938 - val_accuracy: 0.1630 - val_loss: 2.2879\n",
      "Epoch 4/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1555 - loss: 2.2868 - val_accuracy: 0.1656 - val_loss: 2.2758\n",
      "Epoch 5/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1618 - loss: 2.2719 - val_accuracy: 0.1718 - val_loss: 2.2512\n",
      "Epoch 6/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1643 - loss: 2.2428 - val_accuracy: 0.1684 - val_loss: 2.2009\n",
      "Epoch 7/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1686 - loss: 2.1872 - val_accuracy: 0.1746 - val_loss: 2.1285\n",
      "Epoch 8/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1780 - loss: 2.1173 - val_accuracy: 0.2032 - val_loss: 2.0751\n",
      "Epoch 9/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2084 - loss: 2.0709 - val_accuracy: 0.2344 - val_loss: 2.0440\n",
      "Epoch 10/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2306 - loss: 2.0408 - val_accuracy: 0.2362 - val_loss: 2.0216\n",
      "Epoch 11/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2433 - loss: 2.0173 - val_accuracy: 0.2610 - val_loss: 1.9987\n",
      "Epoch 12/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2570 - loss: 1.9879 - val_accuracy: 0.2700 - val_loss: 1.9736\n",
      "Epoch 13/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2716 - loss: 1.9597 - val_accuracy: 0.2794 - val_loss: 1.9476\n",
      "Epoch 14/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2927 - loss: 1.9199 - val_accuracy: 0.3034 - val_loss: 1.9029\n",
      "Epoch 15/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3051 - loss: 1.8903 - val_accuracy: 0.3102 - val_loss: 1.8734\n",
      "Epoch 16/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3118 - loss: 1.8629 - val_accuracy: 0.3078 - val_loss: 1.8562\n",
      "Epoch 17/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3220 - loss: 1.8427 - val_accuracy: 0.3302 - val_loss: 1.8353\n",
      "Epoch 18/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3320 - loss: 1.8177 - val_accuracy: 0.3368 - val_loss: 1.8132\n",
      "Epoch 19/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3386 - loss: 1.8032 - val_accuracy: 0.3340 - val_loss: 1.8185\n",
      "Epoch 20/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3384 - loss: 1.7963 - val_accuracy: 0.3432 - val_loss: 1.7905\n",
      "Epoch 21/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3507 - loss: 1.7742 - val_accuracy: 0.3416 - val_loss: 1.7845\n",
      "Epoch 22/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3551 - loss: 1.7527 - val_accuracy: 0.3500 - val_loss: 1.7826\n",
      "Epoch 23/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3622 - loss: 1.7413 - val_accuracy: 0.3568 - val_loss: 1.7561\n",
      "Epoch 24/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3678 - loss: 1.7358 - val_accuracy: 0.3676 - val_loss: 1.7307\n",
      "Epoch 25/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3770 - loss: 1.7035 - val_accuracy: 0.3728 - val_loss: 1.7151\n",
      "Epoch 26/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3815 - loss: 1.7034 - val_accuracy: 0.3754 - val_loss: 1.7089\n",
      "Epoch 27/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3872 - loss: 1.6806 - val_accuracy: 0.3876 - val_loss: 1.6849\n",
      "Epoch 28/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3925 - loss: 1.6712 - val_accuracy: 0.3798 - val_loss: 1.6839\n",
      "Epoch 29/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3946 - loss: 1.6573 - val_accuracy: 0.3812 - val_loss: 1.7062\n",
      "Epoch 30/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3974 - loss: 1.6608 - val_accuracy: 0.3892 - val_loss: 1.6635\n",
      "Epoch 31/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4048 - loss: 1.6378 - val_accuracy: 0.3912 - val_loss: 1.6529\n",
      "Epoch 32/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4062 - loss: 1.6377 - val_accuracy: 0.3968 - val_loss: 1.6439\n",
      "Epoch 33/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4055 - loss: 1.6259 - val_accuracy: 0.3914 - val_loss: 1.6653\n",
      "Epoch 34/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4093 - loss: 1.6258 - val_accuracy: 0.4044 - val_loss: 1.6295\n",
      "Epoch 35/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4147 - loss: 1.6057 - val_accuracy: 0.4040 - val_loss: 1.6306\n",
      "Epoch 36/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4231 - loss: 1.5830 - val_accuracy: 0.4024 - val_loss: 1.6332\n",
      "Epoch 37/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4196 - loss: 1.5837 - val_accuracy: 0.4138 - val_loss: 1.6043\n",
      "Epoch 38/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4221 - loss: 1.5777 - val_accuracy: 0.4146 - val_loss: 1.6053\n",
      "Epoch 39/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4259 - loss: 1.5675 - val_accuracy: 0.3988 - val_loss: 1.6588\n",
      "Epoch 40/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4311 - loss: 1.5618 - val_accuracy: 0.4180 - val_loss: 1.5918\n",
      "Epoch 41/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4310 - loss: 1.5553 - val_accuracy: 0.4132 - val_loss: 1.5963\n",
      "Epoch 42/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4381 - loss: 1.5430 - val_accuracy: 0.4170 - val_loss: 1.5920\n",
      "Epoch 43/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4397 - loss: 1.5343 - val_accuracy: 0.4188 - val_loss: 1.5952\n",
      "Epoch 44/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4395 - loss: 1.5302 - val_accuracy: 0.4230 - val_loss: 1.5832\n",
      "Epoch 45/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4420 - loss: 1.5240 - val_accuracy: 0.4340 - val_loss: 1.5543\n",
      "Epoch 46/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4460 - loss: 1.5138 - val_accuracy: 0.4296 - val_loss: 1.5714\n",
      "Epoch 47/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4490 - loss: 1.5130 - val_accuracy: 0.4254 - val_loss: 1.5627\n",
      "Epoch 48/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4508 - loss: 1.4951 - val_accuracy: 0.4384 - val_loss: 1.5358\n",
      "Epoch 49/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4533 - loss: 1.4958 - val_accuracy: 0.4330 - val_loss: 1.5557\n",
      "Epoch 50/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4594 - loss: 1.4784 - val_accuracy: 0.4348 - val_loss: 1.5440\n",
      "Epoch 51/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4594 - loss: 1.4756 - val_accuracy: 0.4360 - val_loss: 1.5385\n",
      "Epoch 52/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4617 - loss: 1.4674 - val_accuracy: 0.4452 - val_loss: 1.5337\n",
      "Epoch 53/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4659 - loss: 1.4629 - val_accuracy: 0.4444 - val_loss: 1.5317\n",
      "Epoch 54/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4676 - loss: 1.4570 - val_accuracy: 0.4442 - val_loss: 1.5267\n",
      "Epoch 55/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4708 - loss: 1.4451 - val_accuracy: 0.4498 - val_loss: 1.5095\n",
      "Epoch 56/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4749 - loss: 1.4393 - val_accuracy: 0.4378 - val_loss: 1.5484\n",
      "Epoch 57/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4792 - loss: 1.4257 - val_accuracy: 0.4520 - val_loss: 1.5050\n",
      "Epoch 58/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4775 - loss: 1.4207 - val_accuracy: 0.4546 - val_loss: 1.5055\n",
      "Epoch 59/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4851 - loss: 1.4121 - val_accuracy: 0.4552 - val_loss: 1.5011\n",
      "Epoch 60/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4895 - loss: 1.4047 - val_accuracy: 0.4542 - val_loss: 1.5202\n",
      "Epoch 61/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4916 - loss: 1.3941 - val_accuracy: 0.4556 - val_loss: 1.5030\n",
      "Epoch 62/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4870 - loss: 1.4013 - val_accuracy: 0.4598 - val_loss: 1.4974\n",
      "Epoch 63/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4906 - loss: 1.3878 - val_accuracy: 0.4488 - val_loss: 1.5358\n",
      "Epoch 64/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4987 - loss: 1.3736 - val_accuracy: 0.4650 - val_loss: 1.4892\n",
      "Epoch 65/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4962 - loss: 1.3826 - val_accuracy: 0.4690 - val_loss: 1.4795\n",
      "Epoch 66/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5043 - loss: 1.3679 - val_accuracy: 0.4674 - val_loss: 1.4700\n",
      "Epoch 67/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5039 - loss: 1.3669 - val_accuracy: 0.4606 - val_loss: 1.4954\n",
      "Epoch 68/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4991 - loss: 1.3672 - val_accuracy: 0.4684 - val_loss: 1.4654\n",
      "Epoch 69/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5060 - loss: 1.3506 - val_accuracy: 0.4716 - val_loss: 1.4782\n",
      "Epoch 70/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5162 - loss: 1.3344 - val_accuracy: 0.4748 - val_loss: 1.4616\n",
      "Epoch 71/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5106 - loss: 1.3502 - val_accuracy: 0.4722 - val_loss: 1.4575\n",
      "Epoch 72/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5156 - loss: 1.3372 - val_accuracy: 0.4730 - val_loss: 1.4653\n",
      "Epoch 73/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5159 - loss: 1.3136 - val_accuracy: 0.4742 - val_loss: 1.4394\n",
      "Epoch 74/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5224 - loss: 1.3132 - val_accuracy: 0.4720 - val_loss: 1.4654\n",
      "Epoch 75/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5218 - loss: 1.3034 - val_accuracy: 0.4706 - val_loss: 1.4841\n",
      "Epoch 76/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5297 - loss: 1.2944 - val_accuracy: 0.4720 - val_loss: 1.4722\n",
      "Epoch 77/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5214 - loss: 1.2968 - val_accuracy: 0.4854 - val_loss: 1.4372\n",
      "Epoch 78/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5272 - loss: 1.2910 - val_accuracy: 0.4634 - val_loss: 1.5488\n",
      "Epoch 79/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5244 - loss: 1.2913 - val_accuracy: 0.4838 - val_loss: 1.4405\n",
      "Epoch 80/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5331 - loss: 1.2721 - val_accuracy: 0.4830 - val_loss: 1.4403\n",
      "Epoch 81/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5351 - loss: 1.2698 - val_accuracy: 0.4722 - val_loss: 1.4792\n",
      "Epoch 82/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5386 - loss: 1.2639 - val_accuracy: 0.4878 - val_loss: 1.4317\n",
      "Epoch 83/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5444 - loss: 1.2516 - val_accuracy: 0.4896 - val_loss: 1.4464\n",
      "Epoch 84/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5375 - loss: 1.2546 - val_accuracy: 0.4918 - val_loss: 1.4259\n",
      "Epoch 85/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5430 - loss: 1.2465 - val_accuracy: 0.4906 - val_loss: 1.4264\n",
      "Epoch 86/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5460 - loss: 1.2368 - val_accuracy: 0.4866 - val_loss: 1.4403\n",
      "Epoch 87/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5486 - loss: 1.2327 - val_accuracy: 0.4874 - val_loss: 1.4294\n",
      "Epoch 88/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5545 - loss: 1.2180 - val_accuracy: 0.4848 - val_loss: 1.4934\n",
      "Epoch 89/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5569 - loss: 1.2216 - val_accuracy: 0.4928 - val_loss: 1.4317\n",
      "Epoch 90/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5583 - loss: 1.2111 - val_accuracy: 0.4806 - val_loss: 1.4614\n",
      "Epoch 91/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5559 - loss: 1.2192 - val_accuracy: 0.4862 - val_loss: 1.4478\n",
      "Epoch 92/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5568 - loss: 1.2126 - val_accuracy: 0.4974 - val_loss: 1.4323\n",
      "Epoch 93/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5652 - loss: 1.1950 - val_accuracy: 0.4908 - val_loss: 1.4360\n",
      "Epoch 94/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5626 - loss: 1.1898 - val_accuracy: 0.4896 - val_loss: 1.4263\n",
      "Epoch 95/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5695 - loss: 1.1814 - val_accuracy: 0.4866 - val_loss: 1.4599\n",
      "Epoch 96/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5667 - loss: 1.1801 - val_accuracy: 0.4992 - val_loss: 1.4154\n",
      "Epoch 97/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5729 - loss: 1.1694 - val_accuracy: 0.4856 - val_loss: 1.4699\n",
      "Epoch 98/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5711 - loss: 1.1808 - val_accuracy: 0.4878 - val_loss: 1.4654\n",
      "Epoch 99/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5749 - loss: 1.1630 - val_accuracy: 0.4956 - val_loss: 1.4322\n",
      "Epoch 100/100\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5771 - loss: 1.1625 - val_accuracy: 0.4932 - val_loss: 1.4325\n",
      "Hyperparams for trial 7: {'learning_rate': 0.001, 'batch_size': 128, 'epochs': 50, 'num_layers': 2, 'neurons': 200, 'optimizer': 'sgd', 'lr_sched': 'poly'}\n",
      "Epoch 1/50\n",
      "\u001b[1m328/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2113 - loss: 2.1722"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 22:31:06.171204: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_222', 56 bytes spill stores, 76 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.2156 - loss: 2.1634 - val_accuracy: 0.3228 - val_loss: 1.9110\n",
      "Epoch 2/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3423 - loss: 1.8670 - val_accuracy: 0.3696 - val_loss: 1.8174\n",
      "Epoch 3/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3758 - loss: 1.7771 - val_accuracy: 0.3902 - val_loss: 1.7464\n",
      "Epoch 4/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3979 - loss: 1.7122 - val_accuracy: 0.4042 - val_loss: 1.6971\n",
      "Epoch 5/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4179 - loss: 1.6568 - val_accuracy: 0.4214 - val_loss: 1.6627\n",
      "Epoch 6/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4318 - loss: 1.6255 - val_accuracy: 0.4250 - val_loss: 1.6224\n",
      "Epoch 7/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4453 - loss: 1.5782 - val_accuracy: 0.4466 - val_loss: 1.5823\n",
      "Epoch 8/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4511 - loss: 1.5551 - val_accuracy: 0.4494 - val_loss: 1.5600\n",
      "Epoch 9/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4649 - loss: 1.5198 - val_accuracy: 0.4554 - val_loss: 1.5359\n",
      "Epoch 10/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4788 - loss: 1.4863 - val_accuracy: 0.4730 - val_loss: 1.5121\n",
      "Epoch 11/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4788 - loss: 1.4690 - val_accuracy: 0.4734 - val_loss: 1.4921\n",
      "Epoch 12/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4908 - loss: 1.4441 - val_accuracy: 0.4724 - val_loss: 1.4964\n",
      "Epoch 13/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4980 - loss: 1.4199 - val_accuracy: 0.4732 - val_loss: 1.4943\n",
      "Epoch 14/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5025 - loss: 1.4081 - val_accuracy: 0.4828 - val_loss: 1.4626\n",
      "Epoch 15/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5126 - loss: 1.3747 - val_accuracy: 0.4664 - val_loss: 1.5056\n",
      "Epoch 16/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5148 - loss: 1.3645 - val_accuracy: 0.4930 - val_loss: 1.4287\n",
      "Epoch 17/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5187 - loss: 1.3600 - val_accuracy: 0.4988 - val_loss: 1.4267\n",
      "Epoch 18/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5278 - loss: 1.3349 - val_accuracy: 0.4808 - val_loss: 1.4698\n",
      "Epoch 19/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5398 - loss: 1.3200 - val_accuracy: 0.4934 - val_loss: 1.4221\n",
      "Epoch 20/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5418 - loss: 1.2984 - val_accuracy: 0.5012 - val_loss: 1.4335\n",
      "Epoch 21/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5411 - loss: 1.2855 - val_accuracy: 0.5140 - val_loss: 1.4058\n",
      "Epoch 22/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5460 - loss: 1.2832 - val_accuracy: 0.5056 - val_loss: 1.4021\n",
      "Epoch 23/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5526 - loss: 1.2684 - val_accuracy: 0.5020 - val_loss: 1.4042\n",
      "Epoch 24/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5573 - loss: 1.2437 - val_accuracy: 0.4808 - val_loss: 1.4847\n",
      "Epoch 25/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5564 - loss: 1.2448 - val_accuracy: 0.5160 - val_loss: 1.3881\n",
      "Epoch 26/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5664 - loss: 1.2279 - val_accuracy: 0.5202 - val_loss: 1.3682\n",
      "Epoch 27/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5679 - loss: 1.2153 - val_accuracy: 0.5254 - val_loss: 1.3494\n",
      "Epoch 28/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5668 - loss: 1.2111 - val_accuracy: 0.4862 - val_loss: 1.4386\n",
      "Epoch 29/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5654 - loss: 1.2212 - val_accuracy: 0.5132 - val_loss: 1.3923\n",
      "Epoch 30/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5733 - loss: 1.2010 - val_accuracy: 0.5070 - val_loss: 1.4035\n",
      "Epoch 31/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5769 - loss: 1.1814 - val_accuracy: 0.5204 - val_loss: 1.3679\n",
      "Epoch 32/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5855 - loss: 1.1652 - val_accuracy: 0.5250 - val_loss: 1.3669\n",
      "Epoch 33/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5899 - loss: 1.1511 - val_accuracy: 0.5136 - val_loss: 1.4083\n",
      "Epoch 34/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6041 - loss: 1.1215 - val_accuracy: 0.4914 - val_loss: 1.5058\n",
      "Epoch 35/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5997 - loss: 1.1215 - val_accuracy: 0.5106 - val_loss: 1.4009\n",
      "Epoch 36/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6182 - loss: 1.0685 - val_accuracy: 0.5192 - val_loss: 1.4287\n",
      "Epoch 37/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6251 - loss: 1.0583 - val_accuracy: 0.5338 - val_loss: 1.3726\n",
      "Epoch 38/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6240 - loss: 1.0602 - val_accuracy: 0.5220 - val_loss: 1.4092\n",
      "Epoch 39/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6318 - loss: 1.0363 - val_accuracy: 0.5302 - val_loss: 1.3823\n",
      "Epoch 40/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6343 - loss: 1.0202 - val_accuracy: 0.5346 - val_loss: 1.3707\n",
      "Epoch 41/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6431 - loss: 0.9988 - val_accuracy: 0.5242 - val_loss: 1.4201\n",
      "Epoch 42/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6514 - loss: 0.9855 - val_accuracy: 0.5398 - val_loss: 1.3503\n",
      "Epoch 43/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6543 - loss: 0.9663 - val_accuracy: 0.5396 - val_loss: 1.3566\n",
      "Epoch 44/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6644 - loss: 0.9479 - val_accuracy: 0.5360 - val_loss: 1.4065\n",
      "Epoch 45/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6703 - loss: 0.9306 - val_accuracy: 0.5300 - val_loss: 1.4010\n",
      "Epoch 46/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6720 - loss: 0.9207 - val_accuracy: 0.5416 - val_loss: 1.3897\n",
      "Epoch 47/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6798 - loss: 0.8977 - val_accuracy: 0.5360 - val_loss: 1.3756\n",
      "Epoch 48/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6917 - loss: 0.8772 - val_accuracy: 0.5224 - val_loss: 1.4679\n",
      "Epoch 49/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6918 - loss: 0.8685 - val_accuracy: 0.5310 - val_loss: 1.4259\n",
      "Epoch 50/50\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6954 - loss: 0.8511 - val_accuracy: 0.5372 - val_loss: 1.3958\n",
      "Hyperparams for trial 8: {'learning_rate': 0.005, 'batch_size': 64, 'epochs': 150, 'num_layers': 6, 'neurons': 600, 'optimizer': 'sgd', 'lr_sched': 'exp'}\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 22:31:42.937863: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_71', 248 bytes spill stores, 248 bytes spill loads\n",
      "\n",
      "2026-02-05 22:31:43.245608: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_71', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2026-02-05 22:31:43.489259: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_362', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "2026-02-05 22:31:43.600433: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_141', 312 bytes spill stores, 312 bytes spill loads\n",
      "\n",
      "2026-02-05 22:31:43.652610: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_362', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2617 - loss: 2.0103 - val_accuracy: 0.3548 - val_loss: 1.8003\n",
      "Epoch 2/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3887 - loss: 1.6897 - val_accuracy: 0.4076 - val_loss: 1.6653\n",
      "Epoch 3/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4257 - loss: 1.5859 - val_accuracy: 0.4440 - val_loss: 1.5530\n",
      "Epoch 4/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4569 - loss: 1.5236 - val_accuracy: 0.4392 - val_loss: 1.5476\n",
      "Epoch 5/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4693 - loss: 1.4737 - val_accuracy: 0.4570 - val_loss: 1.5129\n",
      "Epoch 6/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4880 - loss: 1.4222 - val_accuracy: 0.4864 - val_loss: 1.4336\n",
      "Epoch 7/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5088 - loss: 1.3707 - val_accuracy: 0.4602 - val_loss: 1.4835\n",
      "Epoch 8/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5213 - loss: 1.3352 - val_accuracy: 0.4966 - val_loss: 1.4092\n",
      "Epoch 9/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5290 - loss: 1.3045 - val_accuracy: 0.4912 - val_loss: 1.4057\n",
      "Epoch 10/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5493 - loss: 1.2643 - val_accuracy: 0.4948 - val_loss: 1.4288\n",
      "Epoch 11/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5568 - loss: 1.2361 - val_accuracy: 0.5294 - val_loss: 1.3451\n",
      "Epoch 12/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5672 - loss: 1.2056 - val_accuracy: 0.5378 - val_loss: 1.3181\n",
      "Epoch 13/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5859 - loss: 1.1569 - val_accuracy: 0.4950 - val_loss: 1.4586\n",
      "Epoch 14/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5889 - loss: 1.1474 - val_accuracy: 0.5120 - val_loss: 1.4593\n",
      "Epoch 15/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6108 - loss: 1.0861 - val_accuracy: 0.5348 - val_loss: 1.3383\n",
      "Epoch 16/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6215 - loss: 1.0557 - val_accuracy: 0.5266 - val_loss: 1.3214\n",
      "Epoch 17/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6364 - loss: 1.0090 - val_accuracy: 0.5340 - val_loss: 1.3548\n",
      "Epoch 18/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6514 - loss: 0.9604 - val_accuracy: 0.5238 - val_loss: 1.3978\n",
      "Epoch 19/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6595 - loss: 0.9486 - val_accuracy: 0.5166 - val_loss: 1.4343\n",
      "Epoch 20/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6754 - loss: 0.8967 - val_accuracy: 0.5188 - val_loss: 1.4332\n",
      "Epoch 21/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6937 - loss: 0.8618 - val_accuracy: 0.5386 - val_loss: 1.4006\n",
      "Epoch 22/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7029 - loss: 0.8289 - val_accuracy: 0.5400 - val_loss: 1.4350\n",
      "Epoch 23/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7220 - loss: 0.7716 - val_accuracy: 0.5244 - val_loss: 1.4976\n",
      "Epoch 24/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7174 - loss: 0.7762 - val_accuracy: 0.5406 - val_loss: 1.5107\n",
      "Epoch 25/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7448 - loss: 0.6979 - val_accuracy: 0.5360 - val_loss: 1.5588\n",
      "Epoch 26/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7562 - loss: 0.6706 - val_accuracy: 0.5258 - val_loss: 1.5919\n",
      "Epoch 27/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7728 - loss: 0.6363 - val_accuracy: 0.5360 - val_loss: 1.5794\n",
      "Epoch 28/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.5752 - val_accuracy: 0.5316 - val_loss: 1.6783\n",
      "Epoch 29/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.5390 - val_accuracy: 0.5138 - val_loss: 1.7578\n",
      "Epoch 30/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8077 - loss: 0.5330 - val_accuracy: 0.5380 - val_loss: 1.7525\n",
      "Epoch 31/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8240 - loss: 0.4875 - val_accuracy: 0.5272 - val_loss: 1.8635\n",
      "Epoch 32/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8421 - loss: 0.4380 - val_accuracy: 0.5224 - val_loss: 1.9341\n",
      "Epoch 33/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.4255 - val_accuracy: 0.5232 - val_loss: 1.9576\n",
      "Epoch 34/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.3984 - val_accuracy: 0.5272 - val_loss: 2.0824\n",
      "Epoch 35/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.3603 - val_accuracy: 0.5224 - val_loss: 2.0915\n",
      "Epoch 36/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8762 - loss: 0.3471 - val_accuracy: 0.5214 - val_loss: 2.1638\n",
      "Epoch 37/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.3281 - val_accuracy: 0.5234 - val_loss: 2.1400\n",
      "Epoch 38/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8943 - loss: 0.2997 - val_accuracy: 0.5128 - val_loss: 2.2814\n",
      "Epoch 39/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8980 - loss: 0.2832 - val_accuracy: 0.5104 - val_loss: 2.3109\n",
      "Epoch 40/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8936 - loss: 0.2951 - val_accuracy: 0.5308 - val_loss: 2.3583\n",
      "Epoch 41/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.2486 - val_accuracy: 0.5310 - val_loss: 2.3898\n",
      "Epoch 42/150\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.2203 - val_accuracy: 0.5196 - val_loss: 2.4257\n",
      "Hyperparams for trial 9: {'learning_rate': 0.005, 'batch_size': 16, 'epochs': 100, 'num_layers': 8, 'neurons': 200, 'optimizer': 'adam', 'lr_sched': 'poly'}\n",
      "Epoch 1/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.1205 - loss: 2.2679 - val_accuracy: 0.1972 - val_loss: 2.0776\n",
      "Epoch 2/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1791 - loss: 2.1104 - val_accuracy: 0.1958 - val_loss: 2.0718\n",
      "Epoch 3/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1813 - loss: 2.0776 - val_accuracy: 0.1888 - val_loss: 2.1227\n",
      "Epoch 4/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1876 - loss: 2.0739 - val_accuracy: 0.1662 - val_loss: 2.0865\n",
      "Epoch 5/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1911 - loss: 2.0621 - val_accuracy: 0.1930 - val_loss: 2.0706\n",
      "Epoch 6/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1643 - loss: 2.1314 - val_accuracy: 0.1064 - val_loss: 2.3070\n",
      "Epoch 7/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0999 - loss: 2.3055 - val_accuracy: 0.0982 - val_loss: 2.3064\n",
      "Epoch 8/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1024 - loss: 2.3037 - val_accuracy: 0.0976 - val_loss: 2.3046\n",
      "Epoch 9/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0981 - loss: 2.3046 - val_accuracy: 0.0986 - val_loss: 2.3056\n",
      "Epoch 10/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0973 - loss: 2.3045 - val_accuracy: 0.0970 - val_loss: 2.3080\n",
      "Epoch 11/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1021 - loss: 2.3046 - val_accuracy: 0.0986 - val_loss: 2.3273\n",
      "Epoch 12/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1002 - loss: 2.3045 - val_accuracy: 0.1036 - val_loss: 2.3272\n",
      "Epoch 13/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0999 - loss: 2.3049 - val_accuracy: 0.1064 - val_loss: 2.3277\n",
      "Epoch 14/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3046 - val_accuracy: 0.0976 - val_loss: 2.3276\n",
      "Epoch 15/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1021 - loss: 2.3046 - val_accuracy: 0.1036 - val_loss: 2.3292\n",
      "Epoch 16/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0983 - loss: 2.3042 - val_accuracy: 0.1024 - val_loss: 2.3289\n",
      "Epoch 17/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0979 - loss: 2.3048 - val_accuracy: 0.0970 - val_loss: 2.3283\n",
      "Epoch 18/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0988 - loss: 2.3044 - val_accuracy: 0.0970 - val_loss: 2.3321\n",
      "Epoch 19/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0983 - loss: 2.3048 - val_accuracy: 0.1064 - val_loss: 2.3290\n",
      "Epoch 20/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1010 - loss: 2.3042 - val_accuracy: 0.1036 - val_loss: 2.3301\n",
      "Epoch 21/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0965 - loss: 2.3046 - val_accuracy: 0.1064 - val_loss: 2.3302\n",
      "Epoch 22/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0977 - loss: 2.3047 - val_accuracy: 0.0976 - val_loss: 2.3294\n",
      "Epoch 23/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0999 - loss: 2.3043 - val_accuracy: 0.1058 - val_loss: 2.3288\n",
      "Epoch 24/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 2.3043 - val_accuracy: 0.0970 - val_loss: 2.3325\n",
      "Epoch 25/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0948 - loss: 2.3052 - val_accuracy: 0.1024 - val_loss: 2.3308\n",
      "Epoch 26/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0968 - loss: 2.3048 - val_accuracy: 0.0976 - val_loss: 2.3316\n",
      "Epoch 27/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3043 - val_accuracy: 0.0986 - val_loss: 2.3319\n",
      "Epoch 28/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1032 - loss: 2.3044 - val_accuracy: 0.1064 - val_loss: 2.3301\n",
      "Epoch 29/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1022 - loss: 2.3045 - val_accuracy: 0.1024 - val_loss: 2.3295\n",
      "Epoch 30/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0969 - loss: 2.3048 - val_accuracy: 0.0976 - val_loss: 2.3286\n",
      "Epoch 31/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0990 - loss: 2.3048 - val_accuracy: 0.0958 - val_loss: 2.3315\n",
      "Epoch 32/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0975 - loss: 2.3050 - val_accuracy: 0.0958 - val_loss: 2.3304\n",
      "Epoch 33/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 2.3045 - val_accuracy: 0.0976 - val_loss: 2.3295\n",
      "Epoch 34/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1006 - loss: 2.3042 - val_accuracy: 0.0950 - val_loss: 2.3291\n",
      "Epoch 35/100\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0971 - loss: 2.3046 - val_accuracy: 0.0976 - val_loss: 2.3296\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "num_trials = 10\n",
    "for trial in range(num_trials):\n",
    "    hps = get_hyperparams(param_dict)\n",
    "    print(f\"Hyperparams for trial {trial}: {hps}\")\n",
    "\n",
    "    lr_og = hps[\"learning_rate\"] # original learning rate for lr schedulers\n",
    "    lr_sched = hps[\"lr_sched\"] # picking a random lr scheduler\n",
    "    \n",
    "    if lr_sched == \"exp\": \n",
    "        lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "            lr_og,\n",
    "            decay_steps=100000,\n",
    "            decay_rate=0.96,\n",
    "            staircase=True)\n",
    "    else:\n",
    "        end_learning_rate = 0.01\n",
    "        decay_steps = 10000\n",
    "        lr_schedule = keras.optimizers.schedules.PolynomialDecay(\n",
    "            lr_og,\n",
    "            decay_steps,\n",
    "            end_learning_rate,\n",
    "            power=0.5)\n",
    "    \n",
    "    model = random_model(neurons=hps['neurons'], num_layers=hps[\"num_layers\"]) # creating the random model\n",
    "\n",
    "    opt = hps[\"optimizer\"] # picking the random optimizer\n",
    "    if opt == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    run_logdir = Path(\"my_logs/manual3\") / f\"trial_{trial}\"\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=30)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=hps['epochs'],\n",
    "        validation_data=(X_valid, y_valid), \n",
    "        callbacks=[tensorboard_cb, early_stopping_cb],\n",
    "        batch_size=hps['batch_size'],\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'hyperparams' : hps,\n",
    "        'final_val_acc' : max(history.history['val_accuracy']),\n",
    "        'final_train_acc' : max(history.history['accuracy']),\n",
    "        'run_id' : trial\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "361d7079-c35d-4271-af4f-cde3aee4ae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-def059352f28b055\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-def059352f28b055\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs/manual2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91a74348-f135-4611-8205-969d774e0bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hyperparams': {'learning_rate': 0.01,\n",
       "   'batch_size': 64,\n",
       "   'epochs': 150,\n",
       "   'num_layers': 4,\n",
       "   'neurons': 400,\n",
       "   'optimizer': 'sgd',\n",
       "   'lr_sched': 'poly'},\n",
       "  'final_val_acc': 0.5307999849319458,\n",
       "  'final_train_acc': 0.8512444496154785,\n",
       "  'run_id': 0},\n",
       " {'hyperparams': {'learning_rate': 0.005,\n",
       "   'batch_size': 64,\n",
       "   'epochs': 100,\n",
       "   'num_layers': 10,\n",
       "   'neurons': 200,\n",
       "   'optimizer': 'sgd',\n",
       "   'lr_sched': 'exp'},\n",
       "  'final_val_acc': 0.5325999855995178,\n",
       "  'final_train_acc': 0.731844425201416,\n",
       "  'run_id': 1},\n",
       " {'hyperparams': {'learning_rate': 0.0001,\n",
       "   'batch_size': 16,\n",
       "   'epochs': 50,\n",
       "   'num_layers': 2,\n",
       "   'neurons': 600,\n",
       "   'optimizer': 'adam',\n",
       "   'lr_sched': 'exp'},\n",
       "  'final_val_acc': 0.5540000200271606,\n",
       "  'final_train_acc': 0.8779777884483337,\n",
       "  'run_id': 2},\n",
       " {'hyperparams': {'learning_rate': 0.0005,\n",
       "   'batch_size': 64,\n",
       "   'epochs': 200,\n",
       "   'num_layers': 6,\n",
       "   'neurons': 400,\n",
       "   'optimizer': 'sgd',\n",
       "   'lr_sched': 'exp'},\n",
       "  'final_val_acc': 0.5436000227928162,\n",
       "  'final_train_acc': 0.7694000005722046,\n",
       "  'run_id': 3},\n",
       " {'hyperparams': {'learning_rate': 0.001,\n",
       "   'batch_size': 32,\n",
       "   'epochs': 150,\n",
       "   'num_layers': 6,\n",
       "   'neurons': 400,\n",
       "   'optimizer': 'sgd',\n",
       "   'lr_sched': 'poly'},\n",
       "  'final_val_acc': 0.5321999788284302,\n",
       "  'final_train_acc': 0.76746666431427,\n",
       "  'run_id': 4},\n",
       " {'hyperparams': {'learning_rate': 0.005,\n",
       "   'batch_size': 128,\n",
       "   'epochs': 50,\n",
       "   'num_layers': 6,\n",
       "   'neurons': 400,\n",
       "   'optimizer': 'adam',\n",
       "   'lr_sched': 'exp'},\n",
       "  'final_val_acc': 0.4465999901294708,\n",
       "  'final_train_acc': 0.46364444494247437,\n",
       "  'run_id': 5},\n",
       " {'hyperparams': {'learning_rate': 0.0001,\n",
       "   'batch_size': 64,\n",
       "   'epochs': 100,\n",
       "   'num_layers': 10,\n",
       "   'neurons': 200,\n",
       "   'optimizer': 'sgd',\n",
       "   'lr_sched': 'exp'},\n",
       "  'final_val_acc': 0.4991999864578247,\n",
       "  'final_train_acc': 0.5780666470527649,\n",
       "  'run_id': 6},\n",
       " {'hyperparams': {'learning_rate': 0.001,\n",
       "   'batch_size': 128,\n",
       "   'epochs': 50,\n",
       "   'num_layers': 2,\n",
       "   'neurons': 200,\n",
       "   'optimizer': 'sgd',\n",
       "   'lr_sched': 'poly'},\n",
       "  'final_val_acc': 0.5415999889373779,\n",
       "  'final_train_acc': 0.6899999976158142,\n",
       "  'run_id': 7},\n",
       " {'hyperparams': {'learning_rate': 0.005,\n",
       "   'batch_size': 64,\n",
       "   'epochs': 150,\n",
       "   'num_layers': 6,\n",
       "   'neurons': 600,\n",
       "   'optimizer': 'sgd',\n",
       "   'lr_sched': 'exp'},\n",
       "  'final_val_acc': 0.5406000018119812,\n",
       "  'final_train_acc': 0.9113555550575256,\n",
       "  'run_id': 8},\n",
       " {'hyperparams': {'learning_rate': 0.005,\n",
       "   'batch_size': 16,\n",
       "   'epochs': 100,\n",
       "   'num_layers': 8,\n",
       "   'neurons': 200,\n",
       "   'optimizer': 'adam',\n",
       "   'lr_sched': 'poly'},\n",
       "  'final_val_acc': 0.1972000002861023,\n",
       "  'final_train_acc': 0.19179999828338623,\n",
       "  'run_id': 9}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
